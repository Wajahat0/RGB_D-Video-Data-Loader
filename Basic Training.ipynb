{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc793da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "import pytorch_lightning\n",
    "# import pytorchvideo.data\n",
    "import torch.utils.data\n",
    "from sklearn.metrics import accuracy_score,auc,roc_auc_score\n",
    "from script.video_data_loader import VideoDataLoader\n",
    "import pytorchvideo.models.resnet\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# import math\n",
    "from script.get_model import get_model\n",
    "\n",
    "from script.transformation import * #ToTensor, CenterCrop_resize, RandomCrop, RandomRotate,RandomHorizontalFlip,RandomVerticalFlip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e6f06b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser(description='Model_training.')\n",
    "# parser.add_argument(\"-r_dir\", \"--root_dir\", help=\"Enter the path to root dir.\", default=r\"D:\\data\")\n",
    "# parser.add_argument(\"-d_dir\", \"--data_dir\", help=\"Enter the path to data dir data\\train.\", default=\"RGB_D\\RGB\")\n",
    "# parser.add_argument(\"-batch_size\", \"--batch_size\", help=\"Enter the batch_size.\", default=32)\n",
    "# parser.add_argument(\"-fps\", \"--frame_rate\", help=\"Enter the desired frame rate.\", default=30)\n",
    "# parser.add_argument(\"-clip_d\", \"--clip_duration\", help=\"Enter the desired frame rate.\", default=16)\n",
    "# parser.add_argument(\"-num_classes\", \"--num_classes\", help=\"Enter Number of classes.\", default=10)\n",
    "# parser.add_argument(\"-model\", \"--model\", help=\"Select from the list ['slow_r50' ,'c2d_r50' ,'r3d_18','slowfast_r50','r2plus1D_18']\", default='r3d_18')\n",
    "# parser.add_argument(\"-weights\", \"--pre_trained\", help=\"Should model use pretrained weights are not True/False.\", default='True')\n",
    "# parser.add_argument(\"-m\", \"--mode\", help=\"Data_type the microscope: RGB, Depth,RGB_D.\", default=\"RGB\")\n",
    "# parser.add_argument(\"-lr\", \"--learning_rate\", help=\"Learning rate screach  0.01, 0.001 transfer Learning\", default=0.001)\n",
    "# parser.add_argument(\"-ep\", \"--epochs\", help=\"Learning rate screach  0.01, 0.001 transfer Learning\", default=100)\n",
    "\n",
    "# args = parser.parse_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d167de76",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "num_frames = 8\n",
    "num_epochs = 10\n",
    "frame_rate = 10\n",
    "image_size = 112\n",
    "num_classes = 60\n",
    "pre_trained= 'r2plus1D_18' #args.model\n",
    "weight = True\n",
    "lr = 0.001  #screach  0.01, 0.001 transfer Learning\n",
    "# patience = 20\n",
    "mode = 'RGB_D'\n",
    "path_to_folder= r'D:\\data'\n",
    "data_folder = r'RGB_D\\RGB'\n",
    "# hello= transform=transforms.Compose([Rescale(256),RandomCrop(224),ToTensor()\n",
    "transform_train=transforms.Compose([ToTensor(num_frames,frame_rate),\n",
    "                                                    CenterCrop_resize(256),RandomCrop(224),RandomHorizontalFlip(0.5),\n",
    "                                                    RandomRotate(30),RandomVerticalFlip(0.5)])\n",
    "\n",
    "transform_test=transforms.Compose([ToTensor(num_frames,frame_rate),\n",
    "                                                    CenterCrop_resize(256)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f44ead2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\data\\RGB_D/RGB\n",
      "D:\\data\\RGB_D/Depth\n",
      "D:\\data\\RGB_D/RGB\n",
      "D:\\data\\RGB_D/Depth\n"
     ]
    }
   ],
   "source": [
    "train_dataset = VideoDataLoader(root_dir=path_to_folder,csv_dir=r'data_files\\RGB_D_train_1.csv', \n",
    "                                transform=transform_train,frame_rate=frame_rate, image_size=image_size, num_frames = num_frames,\n",
    "                                mode=mode)\n",
    "\n",
    "test_dataset = VideoDataLoader(root_dir=path_to_folder,csv_dir=r'data_files\\RGB_D_test_1.csv',\n",
    "                               transform=transform_test,frame_rate=frame_rate, image_size=image_size, num_frames = num_frames,\n",
    "                               mode=mode)\n",
    "\n",
    "\n",
    "# print(len(train_dataset))\n",
    "\n",
    "train = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, num_workers=0,pin_memory=True)\n",
    "test = DataLoader(test_dataset, batch_size=batch_size,shuffle=True, num_workers=0,pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47de01b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36e010d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VideoResNet(\n",
       "  (stem): BasicStem(\n",
       "    (0): Conv3d(4, 64, kernel_size=(3, 7, 7), stride=(1, 2, 2), padding=(1, 3, 3), bias=False)\n",
       "    (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=60, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net= get_model(pretrained_model='r3d_18',num_classes=num_classes, weight=weight,mode='RGB_D')\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d5ca286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4, 8, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "for data in train:\n",
    "    print(data['videos'].shape)  \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12bd81cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.path.exists(r\"C:\\Users\\wajah\\Desktop\\Training\\model\\r3d_18_self.pth\"):\n",
    "    print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b70f131",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[43mmodel_path\u001b[49m):\n\u001b[0;32m      2\u001b[0m     net \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(model_path)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_path' is not defined"
     ]
    }
   ],
   "source": [
    "if os.path.exists(model_path):\n",
    "    net = torch.load(model_path)\n",
    "else:\n",
    "    net = get_model(pretrained_model=pre_trained,num_classes=num_classes, weight=weight,mode=args.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a238f60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daea2c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_kinetics_resnet():\n",
    "#   return pytorchvideo.models.resnet.create_resnet(\n",
    "#       input_channel=4, # RGB input from Kinetics\n",
    "#       model_depth=101, # For the tutorial let's just use a 50 layer network\n",
    "#       model_num_class=60, # Kinetics has 400 classes so we need out final head to align\n",
    "#       norm=nn.BatchNorm3d,\n",
    "#       activation=nn.ReLU,\n",
    "#   )\n",
    "\n",
    "# model = make_kinetics_resnet()\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b02084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "scheduler = StepLR(optimizer, step_size=20, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4660633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_loop(model, train_dataloader, device, optimizer, criterion):\n",
    "    \"\"\"\n",
    "    One Iteration across the training set\n",
    "    Args:\n",
    "        :param model: solution.Basset()\n",
    "        :param train_dataloader: torch.utils.data.DataLoader\n",
    "                                 Where the dataset is solution.BassetDataset\n",
    "        :param device: torch.device\n",
    "        :param optimizer: torch.optim\n",
    "        :param critereon: torch.nn (output of get_critereon)\n",
    "\n",
    "    :Returns: output dict with keys: total_score, total_loss\n",
    "    values of each should be floats\n",
    "    (if you want to display losses and/or scores within the loop, you may print them to screen)\n",
    "\n",
    "    Make sure your loop works with arbitrarily small dataset sizes!\n",
    "\n",
    "    Note: you don’t need to compute the score after each training iteration.\n",
    "    If you do this, your training loop will be really slow!\n",
    "    You should instead compute it every 50 or so iterations and aggregate ...\n",
    "    \"\"\"\n",
    "\n",
    "#     output = {'total_score': 0.,\n",
    "#               'total_loss': 0.}\n",
    "    model.train()\n",
    "    LOSSES = 0\n",
    "    COUNTER = 0\n",
    "    ITERATIONS = 0\n",
    "    p_labels = torch.tensor(()).to(device)\n",
    "    y_labels = torch.tensor(()).to(device)\n",
    "    \n",
    "#     for i,data in enumerate(train_dataloader,0):\n",
    "    with tqdm(train_dataloader, unit=\"batch\") as tepoch:\n",
    "        for data in tepoch:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            inputs, y_true = data['videos'].to(device), data['labels'].to(device)\n",
    "            outputs = net(inputs)\n",
    "            _,y_pred = torch.max(outputs,1)\n",
    "            loss = criterion(outputs, y_true.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            n = y_true.size(0)  #total number training example in batch\n",
    "            LOSSES += loss.sum().data.cpu() * n        \n",
    "            y_labels = torch.cat((y_labels, y_true.long()), 0)\n",
    "            p_labels = torch.cat((p_labels, y_pred), 0)\n",
    "            tepoch.set_postfix(loss=loss.item())\n",
    "            COUNTER += n\n",
    "#             if COUNTER == 20:\n",
    "#                 break\n",
    "\n",
    "        \n",
    "        y_labels = y_labels.cpu()\n",
    "        p_labels = p_labels.cpu()\n",
    "        p_labels= p_labels.detach().numpy()\n",
    "        y_labels = y_labels.detach().numpy()\n",
    "    \n",
    "        x = accuracy_score(y_labels, p_labels) #roc_auc_score#\n",
    "        \n",
    "    \n",
    "\n",
    "        \n",
    "    return x, LOSSES / float(COUNTER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d000b42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_loop(model, valid_dataloader, device, optimizer, criterion):\n",
    "    \"\"\"\n",
    "    One Iteration across the training set\n",
    "    Args:\n",
    "        :param model: solution.Basset()\n",
    "        :param train_dataloader: torch.utils.data.DataLoader\n",
    "                                 Where the dataset is solution.BassetDataset\n",
    "        :param device: torch.device\n",
    "        :param optimizer: torch.optim\n",
    "        :param critereon: torch.nn (output of get_critereon)\n",
    "\n",
    "    :Returns: output dict with keys: total_score, total_loss\n",
    "    values of each should be floats\n",
    "    (if you want to display losses and/or scores within the loop, you may print them to screen)\n",
    "\n",
    "    Make sure your loop works with arbitrarily small dataset sizes!\n",
    "\n",
    "    Note: you don’t need to compute the score after each training iteration.\n",
    "    If you do this, your training loop will be really slow!\n",
    "    You should instead compute it every 50 or so iterations and aggregate ...\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    LOSSES = 0\n",
    "    COUNTER = 0\n",
    "    ITERATIONS = 0\n",
    "    p_labels = torch.tensor(()).to(device)\n",
    "    y_labels = torch.tensor(()).to(device)\n",
    "    with torch.no_grad():\n",
    "        with tqdm(valid_dataloader, unit=\"batch\") as tepoch:\n",
    "#         for i,data in enumerate(valid_dataloader,0):\n",
    "            for data in tepoch:\n",
    "                inputs, y_true = data['videos'].to(device), data['labels'].to(device)\n",
    "                outputs = net(inputs.to(torch.float32))\n",
    "                _,y_pred = torch.max(outputs,1)\n",
    "                loss = criterion(outputs, y_true.long())\n",
    "#                 writer.add_scalar(\"Loss/validation\", loss, epoch)\n",
    "            \n",
    "                n = y_true.size(0)  #total number training example in batch\n",
    "                LOSSES += loss.sum().data.cpu() * n        \n",
    "                y_labels = torch.cat((y_labels, y_true.long()), 0)\n",
    "                p_labels = torch.cat((p_labels, y_pred), 0)\n",
    "                COUNTER += n\n",
    "                \n",
    "                if COUNTER==20:\n",
    "                    break\n",
    "\n",
    "\n",
    "    y_labels = y_labels.cpu()\n",
    "    p_labels = p_labels.cpu()\n",
    "    p_labels= p_labels.detach().numpy()\n",
    "    y_labels = y_labels.detach().numpy()\n",
    "    \n",
    "    x = accuracy_score(y_labels, p_labels)\n",
    "    return x, LOSSES / float(COUNTER)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812cafdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1f9429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "v_loss= np.array(10.0)\n",
    "\n",
    "train_losses, valid_losses = [], []\n",
    "train_accuracy, valid_accuracy = [], []\n",
    "for epoch in range(num_epochs):\n",
    "    tqdm.write(f\"====== Epoch {epoch} ======>\")\n",
    "    \n",
    "    train_acc,train_loss = train_loop(net, train, device, optimizer, criterion)\n",
    "    valid_acc,valid_loss = valid_loop(net, train, device, optimizer, criterion)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracy.append(train_acc)\n",
    "    valid_losses.append(valid_loss)\n",
    "    valid_accuracy.append(valid_acc)\n",
    "    if v_loss>valid_loss.cpu().numpy():\n",
    "        v_loss=valid_loss.cpu().numpy()\n",
    "        torch.save(net,'r3d_18_self.pth')\n",
    "        print('validation loss improved and new model is saved')\n",
    "    \n",
    "    \n",
    "    print('validation_loss',valid_loss)\n",
    "    curr_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    print(f'Epoch {epoch}\\ \\\n",
    "        Training Loss: {train_loss}\\ \\\n",
    "        Training Accuracy: {train_acc}\\ \\\n",
    "        Validation Loss:{valid_loss}\\ \\\n",
    "        Validation Loss:{valid_acc}\\ \\\n",
    "        LR:{curr_lr}')\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "print(f\"===== Best validation loss: {min(valid_losses):.3f} =====>\")\n",
    "print(f\"===== Best validation Accuracy: {max(valid_accuracy):.3f} =====>\")\n",
    "writer.flush()    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0476687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"===== Best validation loss: {min(valid_losses):.3f} =====>\")\n",
    "# print(f\"===== Best validation Accuracy: {max(train_accuracy):.3f} =====>\")\n",
    "writer.close()\n",
    "# !pip install tensorboard\n",
    "# import tensorboard\n",
    "# tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c55ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "for param in net.parameters():\n",
    "#     if i < 45:\n",
    "    param.requires_grad = True\n",
    "#         print(name)\n",
    "#     i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4aab8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# v_loss= np.array(10.0)\n",
    "# train_losses, valid_losses = [], []\n",
    "# train_accuracy, valid_accuracy = [], []\n",
    "for epoch in range(num_epochs):\n",
    "    tqdm.write(f\"====== Epoch {epoch} ======>\")\n",
    "    \n",
    "    train_acc,train_loss = train_loop(net, train_datagen, device, optimizer, criterion)\n",
    "    valid_acc,valid_loss = valid_loop(net, test_datagen, device, optimizer, criterion)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracy.append(train_acc)\n",
    "    valid_losses.append(valid_loss)\n",
    "    valid_accuracy.append(valid_acc)\n",
    "    if v_loss>valid_loss.cpu().numpy():\n",
    "        v_loss=valid_loss.cpu().numpy()\n",
    "        torch.save(net,'r3d_18_aug.pth')\n",
    "        print('validation loss improved and new model is saved')\n",
    "    \n",
    "    \n",
    "    print('validation_loss',valid_loss)\n",
    "    curr_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    print(f'Epoch {epoch}\\ \\\n",
    "        Training Loss: {train_loss}\\ \\\n",
    "        Training Accuracy: {train_acc}\\ \\\n",
    "        Validation Loss:{valid_loss}\\ \\\n",
    "        Validation Loss:{valid_acc}\\ \\\n",
    "        LR:{curr_lr}')\n",
    "\n",
    "    scheduler.step(valid_loss)\n",
    "\n",
    "print(f\"===== Best validation loss: {min(valid_losses):.3f} =====>\")\n",
    "print(f\"===== Best validation Accuracy: {max(valid_accuracy):.3f} =====>\")\n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370d5a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(valid_acc, valid_loss)\n",
    "\n",
    "torch.save(net,'r3d_18.pth')\n",
    "import numpy as np\n",
    "loss= []\n",
    "np.save('r3d_18.npy',np.array(loss.append([train_losses, train_accuracy,valid_losses, valid_accuracy])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ce9e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"===== Best validation loss: {min(train_losses):.3f} =====>\")\n",
    "print(f\"===== Best validation Accuracy: {max(train_accuracy):.3f} =====>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200c0909",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = np.load('test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55431e31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "lw = 2\n",
    "alpha=0.6\n",
    "epochs = range(0,num_epochs)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, num=None, figsize=(14, 6), dpi=200, facecolor='w', edgecolor='k')\n",
    "ax = axs[1]\n",
    "\n",
    "\n",
    "ax.plot(epochs, train_losses, 'green', label='Training Loss', linestyle='solid', linewidth=lw)\n",
    "ax.plot(epochs, valid_losses, 'green', label='Validation Loss',linestyle='dashed', linewidth=lw)\n",
    "\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "#     plt.ylim([0,20])\n",
    "ax.grid(True)\n",
    "ax.set_title(f\"Training and Validation Loss\")\n",
    "# ax.legend(handlelength=2)\n",
    "ax.legend(loc='best', bbox_to_anchor=(0., -0.22, 1., .102),\n",
    "           ncol=2, mode=\"expand\", fontsize='small', borderaxespad=0.)\n",
    "\n",
    "\n",
    "\n",
    "ax = axs[0]\n",
    "\n",
    "\n",
    "ax.plot(epochs, train_accuracy, 'red', label='Training Loss', linestyle='solid', linewidth=lw)\n",
    "ax.plot(epochs, valid_accuracy, 'red', label='Validation Loss',linestyle='dashed', linewidth=lw)\n",
    "\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Accuracy')\n",
    "#     plt.ylim([0,20])\n",
    "ax.grid(True)\n",
    "ax.set_title(f\"Training and Validation Accuracy:  {valid_acc:.3f}%\")\n",
    "# ax.legend(handlelength=2)\n",
    "ax.legend(loc='best', bbox_to_anchor=(0., -0.22, 1., .102),\n",
    "           ncol=2, mode=\"expand\", fontsize='small', borderaxespad=0.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adffc1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, r'C:\\Users\\wajah\\Desktop\\pytorch_model\\model\\r3d_18.pth') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a812384",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net,'r3d_18.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99930fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(v_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1bb9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(valid_loss.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8137f7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "for x in range(100):\n",
    "    print(random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3893c012",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
